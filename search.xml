<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>链表</title>
    <url>/uncategorized/%E8%AE%BA%E6%96%87%E6%B5%85%E5%B0%9D%7C%20word2vec%20%E5%8F%82%E6%95%B0%E5%AD%A6%E4%B9%A0%E8%AF%B4%E6%98%8E/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="/assets/js/Meting.min.js"></script><blockquote>
<p>word2vec 的模型和应用近年来备受关注。通过 word2vec 习得 words 的矢量表示在各 NLP 任务中都很受用。甚至由于谷歌的大牌效应，提到词向量就会想到 word2vec。但大家多把 word2vec 当作一个获取词向量的工具来使用，并未过多关心其模型本身。虽然作为语言模型而言其较为粗糙，但详细了解单词嵌入模型的参数学习过程，有助于了解此类似技术的工作机制。</p>
</blockquote>
<p>论文题目：word2vec Parameter Learning Explained<br>
论文链接：<a href="https://arxiv.org/pdf/1411.2738.pdf">https://arxiv.org/pdf/1411.2738.pdf</a><br>
![](/upload_image/word2vec 01.png)</p>
]]></content>
  </entry>
</search>
